{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#introduction","title":"Introduction","text":"<p>In this project, I created a simple ETL data pipeline to work with different types of datasets. The pipeline takes the data, changes it into a clean format, and saves it as CSV files. All steps of the process are written into a log file, so it is easy to follow what happened and fix problems if needed.</p>"},{"location":"#data-flow","title":"Data Flow","text":""},{"location":"#folder-structure","title":"Folder Structure","text":"<pre><code>SimpleDataFlow/\n\u2502\n\u251c\u2500\u2500 data/                  \n\u2502   \u251c\u2500\u2500 raw/               \n\u2502   \u2514\u2500\u2500 processed/         \n\u2502\n\u251c\u2500\u2500 logs/                  \n\u2502   \u2514\u2500\u2500 log_file.txt\n\u2502\n\u251c\u2500\u2500 docs/ \n\u2502   \u251c\u2500\u2500 pipline.md\n\u2502   \u2514\u2500\u2500 index.md\n\u2502\n\u251c\u2500\u2500 src/                     \n\u2502   \u2514\u2500\u2500 etl.py\n\u2502\n\u251c\u2500\u2500 requirements.txt       \n\u251c\u2500\u2500 README.md              \n\u251c\u2500\u2500 mkdocs.yaml\n\u2514\u2500\u2500 LICANSE      \n</code></pre>"},{"location":"pipline/","title":"simply_ETL Pipeline Steps","text":"<p>This is simple description of ETL pipeline for this project.</p>"},{"location":"pipline/#1-extract-step","title":"1. Extract step","text":"<ul> <li>Scan current folder for CSV, JSON and XML files  </li> <li>Read data from each file type using different functions  </li> <li>Combine all data to one big DataFrame  </li> </ul>"},{"location":"pipline/#2-transform-step","title":"2. Transform step","text":"<ul> <li>Convert height from inches to meters (1 inch = 0.0254 meters)  </li> <li>Convert weight from pounds to kilograms (1 pound = 0.45359237 kg)  </li> <li>Round values to 2 decimal points  </li> </ul>"},{"location":"pipline/#3-load-step","title":"3. Load step","text":"<ul> <li>Save the transformed DataFrame to CSV file called <code>transformed_data.csv</code> </li> </ul>"},{"location":"pipline/#4-logging","title":"4. Logging","text":"<ul> <li>Each phase (extract, transform, load) is logged with timestamp to <code>log_file.txt</code> </li> <li>Helps to track progress and debugging  </li> </ul> <p>You can run the ETL by executing <code>etl.py</code> script in terminal.</p>"}]}
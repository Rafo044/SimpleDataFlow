{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"simply_ETL Project Overview This project is simple ETL pipeline for transform data from multiple source files (csv, json, xml) to one csv file. What is ETL? ETL mean Extract, Transform and Load. - Extract: Get data from sources - Transform: Change data to needed form - Load: Save data to target file or database Data sources We use three type files: - CSV (source1.csv, source2.csv, source3.csv) - JSON (source1.json, source2.json, source3.json) - XML (source.xml) All files contain same data but different formats. ETL process schema Below image shows ETL steps in pipeline: First we extract data from all source files Then transform heights and weights units Finally load all data to transformed_data.csv","title":"simply_ETL Project Overview"},{"location":"#simply_etl-project-overview","text":"This project is simple ETL pipeline for transform data from multiple source files (csv, json, xml) to one csv file.","title":"simply_ETL Project Overview"},{"location":"#what-is-etl","text":"ETL mean Extract, Transform and Load. - Extract: Get data from sources - Transform: Change data to needed form - Load: Save data to target file or database","title":"What is ETL?"},{"location":"#data-sources","text":"We use three type files: - CSV (source1.csv, source2.csv, source3.csv) - JSON (source1.json, source2.json, source3.json) - XML (source.xml) All files contain same data but different formats.","title":"Data sources"},{"location":"#etl-process-schema","text":"Below image shows ETL steps in pipeline: First we extract data from all source files Then transform heights and weights units Finally load all data to transformed_data.csv","title":"ETL process schema"},{"location":"pipline/","text":"simply_ETL Pipeline Steps This is simple description of ETL pipeline for this project. 1. Extract step Scan current folder for CSV, JSON and XML files Read data from each file type using different functions Combine all data to one big DataFrame 2. Transform step Convert height from inches to meters (1 inch = 0.0254 meters) Convert weight from pounds to kilograms (1 pound = 0.45359237 kg) Round values to 2 decimal points 3. Load step Save the transformed DataFrame to CSV file called transformed_data.csv 4. Logging Each phase (extract, transform, load) is logged with timestamp to log_file.txt Helps to track progress and debugging You can run the ETL by executing etl.py script in terminal.","title":"simply_ETL Pipeline Steps"},{"location":"pipline/#simply_etl-pipeline-steps","text":"This is simple description of ETL pipeline for this project.","title":"simply_ETL Pipeline Steps"},{"location":"pipline/#1-extract-step","text":"Scan current folder for CSV, JSON and XML files Read data from each file type using different functions Combine all data to one big DataFrame","title":"1. Extract step"},{"location":"pipline/#2-transform-step","text":"Convert height from inches to meters (1 inch = 0.0254 meters) Convert weight from pounds to kilograms (1 pound = 0.45359237 kg) Round values to 2 decimal points","title":"2. Transform step"},{"location":"pipline/#3-load-step","text":"Save the transformed DataFrame to CSV file called transformed_data.csv","title":"3. Load step"},{"location":"pipline/#4-logging","text":"Each phase (extract, transform, load) is logged with timestamp to log_file.txt Helps to track progress and debugging You can run the ETL by executing etl.py script in terminal.","title":"4. Logging"}]}